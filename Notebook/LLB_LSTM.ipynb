{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LLB-LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "DETD8hzD_ZWt"
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import gym\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn as nn\n",
        "from torch.distributions.relaxed_bernoulli import RelaxedBernoulli\n",
        "from torch.distributions import Bernoulli\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.utils.rnn import pack_padded_sequence as pack\n",
        "from torch.autograd import Variable\n",
        "\n",
        "from torch.nn.utils.rnn import pack_padded_sequence as pack\n",
        "from torch.distributions import Normal\n",
        "from torch.distributions import MultivariateNormal\n",
        "from torch.distributions.kl import kl_divergence\n",
        "\n",
        "from torch.autograd import Variable\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "import time"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZ78kOcy_lPt"
      },
      "source": [
        "#Some tools"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrS967N__mtx"
      },
      "source": [
        "def padding_tensor(sequences):\n",
        "    \"\"\"\n",
        "    :param sequences: list of tensors with shape [seq, state dim]\n",
        "    :return: tensor with shape [num, max_seq_length, state dim]\n",
        "    \"\"\"\n",
        "    num = len(sequences)\n",
        "    max_len = max([s.size(0) for s in sequences])\n",
        "    feature_dim = sequences[0].size(-1)\n",
        "    out_dims = (num, max_len, feature_dim)\n",
        "\n",
        "    out_tensor = sequences[0].data.new(*out_dims).fill_(0)\n",
        "\n",
        "    mask = sequences[0].data.new(*out_dims).fill_(0)\n",
        "    for i, tensor in enumerate(sequences):\n",
        "        length = tensor.size(0)\n",
        "        out_tensor[i, :length, :] = tensor\n",
        "        mask[i, :length,:] = 1\n",
        "    return out_tensor, mask\n",
        "\n",
        "\n",
        "def truncate_sequence(list_of_sequence, batch_first, min_len=None):\n",
        "    \"\"\"\n",
        "    list_of_sequence: list of tensor with shape [seq, feature dim]\n",
        "    return : tensor with shape [min_seq_length, batch, fea_dim] or [batch, min_seq_length, fea_dim] if batch_first\n",
        "    \"\"\"\n",
        "    feature_dim = list_of_sequence[0].size(-1)\n",
        "    if min_len is None:\n",
        "        min_len = min([s.size(0) for s in list_of_sequence])\n",
        "        \n",
        "    container = torch.zeros(len(list_of_sequence), min_len, feature_dim)\n",
        "    for i in range(len(list_of_sequence)):\n",
        "        #random truncation\n",
        "        #start = np.random.choice((list_of_sequence[i].size(0) - min_len +1))\n",
        "        #container[i] = list_of_sequence[i][start : start+min_len, :]\n",
        "\n",
        "        container[i] = list_of_sequence[i][:min_len,:]\n",
        "\n",
        "    \n",
        "    if batch_first:\n",
        "        return container\n",
        "    else:\n",
        "        return container.permute(1,0,2)\n",
        "\n",
        "\n",
        "\n",
        "def plot_LLB(true_obs, mean, std):\n",
        "\n",
        "    position = true_obs[1:,0,0].data.numpy()\n",
        "    velocity = true_obs[1:,0,1].data.numpy()\n",
        "    angle = true_obs[1:,0,2].data.numpy()\n",
        "    angle_v = true_obs[1:,0,3].data.numpy()\n",
        "\n",
        "    lower = mean - std      #[seq-1, output_dim]\n",
        "    upper = mean + std\n",
        "    position_mean = mean[:,0].data.cpu().numpy()\n",
        "    velocity_mean = mean[:,1].data.cpu().numpy()\n",
        "    angle_mean = mean[:,2].data.cpu().numpy()\n",
        "    angle_v_mean = mean[:,3].data.cpu().numpy()\n",
        "\n",
        "    lower_position = lower[:,0].data.cpu().numpy()\n",
        "    lower_velocity = lower[:,1].data.cpu().numpy()\n",
        "    lower_angle = lower[:,2].data.cpu().numpy()\n",
        "    lower_angle_v = lower[:,3].data.cpu().numpy()\n",
        "\n",
        "\n",
        "    upper_position = upper[:,0].data.cpu().numpy()\n",
        "    upper_velocity = upper[:,1].data.cpu().numpy()\n",
        "    upper_angle = upper[:,2].data.cpu().numpy()\n",
        "    upper_angle_v = upper[:,3].data.cpu().numpy()\n",
        "\n",
        "    fig, ax = plt.subplots(1,4, figsize = (20,5))\n",
        "    x = np.arange(0, position.shape[0])\n",
        "\n",
        "    ax[0].plot(position, label = 'True')\n",
        "    ax[0].plot(x, position_mean, label = 'mean')\n",
        "    ax[0].fill_between(x, upper_position, lower_position, facecolor='grey',\n",
        "                                    color = 'grey', alpha = 0.2)\n",
        "    ax[0].set_title('Position');\n",
        "    ax[0].legend();\n",
        "\n",
        "    ax[1].plot(velocity, label = 'True')\n",
        "    ax[1].plot(x, velocity_mean, label = 'mean')\n",
        "    ax[1].fill_between(x, upper_velocity, lower_velocity, facecolor='grey',\n",
        "                                    color = 'grey', alpha = 0.2)\n",
        "    ax[1].set_title('Velocity')\n",
        "    ax[1].legend();\n",
        "\n",
        "\n",
        "    ax[2].plot(angle, label = 'True')\n",
        "    ax[2].plot(x, angle_mean, label = 'mean')\n",
        "    ax[2].fill_between(x, upper_angle, lower_angle, facecolor='grey',\n",
        "                                    color = 'grey', alpha = 0.2)\n",
        "    ax[2].set_title('angle')\n",
        "    ax[2].legend();\n",
        "\n",
        "    ax[3].plot(angle_v, label = 'True')\n",
        "    ax[3].plot(x, angle_v_mean, label = 'mean')\n",
        "    ax[3].fill_between(x, upper_angle_v, lower_angle_v, facecolor='grey',\n",
        "                                    color = 'grey', alpha = 0.2)\n",
        "    ax[3].set_title('angle velocity')\n",
        "    ax[3].legend();\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def save_model_policy(model, model_optimiser, policy, policy_optimiser, save_model_path, save_policy_path):\n",
        "    save_model_path = save_model_path + \"/model.tar\"\n",
        "    save_policy_path = save_policy_path + \"/policy.tar\" \n",
        "    torch.save({\n",
        "        \"model_dict\": model.state_dict(),\n",
        "        \"trainer_dict\": model_optimiser.state_dict()\n",
        "    }, save_model_path)\n",
        "\n",
        "    torch.save({\n",
        "        \"model_dict\": policy.state_dict(),\n",
        "        \"trainer_dict\": policy_optimiser.state_dict()\n",
        "    }, save_policy_path)\n",
        "\n",
        "\n",
        "\n",
        "    print('Checkpointed')\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AMIDU1FR_rh6"
      },
      "source": [
        "#env"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KVBx02Ce_bo7"
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Classic cart-pole system implemented by Rich Sutton et al.\n",
        "Copied from http://incompleteideas.net/sutton/book/code/pole.c\n",
        "permalink: https://perma.cc/C9ZM-652R\n",
        "Modified by Aaditya Ravindran to include friction and random sensor & actuator noise\n",
        "\"\"\"\n",
        "\n",
        "import logging\n",
        "import math\n",
        "import random\n",
        "import gym\n",
        "from gym import spaces\n",
        "from gym.utils import seeding\n",
        "import numpy as np\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "class CartPoleModEnv(gym.Env):\n",
        "    metadata = {\n",
        "            'render.modes': ['human', 'rgb_array'],\n",
        "            'video.frames_per_second' : 50\n",
        "    }\n",
        "\n",
        "    def __init__(self,case):\n",
        "        self.__version__ = \"0.2.0\"\n",
        "        print(\"CartPoleModEnv - Version {}, Noise case: {}\".format(self.__version__,case))\n",
        "        self.gravity = 9.8\n",
        "        self.masscart = 1.0\n",
        "        self.masspole = 0.1\n",
        "        self.total_mass = (self.masspole + self.masscart)\n",
        "        self.length = 0.5 # actually half the pole's length\n",
        "        self.polemass_length = (self.masspole * self.length)\n",
        "        self.seed()\n",
        "\n",
        "        self.origin_case = case\n",
        "        if case<6:          #only model  noise\n",
        "            self.force_mag = 30.0*(1+self.addnoise(case))\n",
        "            self.case = 1\n",
        "        elif case>9:    #both model and data noise\n",
        "            self.force_mag = 30.0*(1+self.addnoise(case))\n",
        "            self.case = 10\n",
        "        else:               #only data noise\n",
        "            self.force_mag = 30.0\n",
        "            self.case = case\n",
        "            \n",
        "        self.tau = 0.02     # seconds between state updates\n",
        "\n",
        "        self.min_action = -1.\n",
        "        self.max_action = 1.0\n",
        "\n",
        "\n",
        "\t\t# Angle at which to fail the episode\n",
        "        self.theta_threshold_radians = 12 * 2 * math.pi / 360\n",
        "        self.x_threshold = 2.4\n",
        "\n",
        "        # Angle limit set to 2 * theta_threshold_radians so failing observation is still within bounds\n",
        "        high = np.array([\n",
        "            self.x_threshold * 2,\n",
        "            np.finfo(np.float32).max,\n",
        "            self.theta_threshold_radians * 2,\n",
        "            np.finfo(np.float32).max])\n",
        "\n",
        "        #self.action_space = spaces.Discrete(2) # AA Set discrete states back to 2\n",
        "        self.action_space = spaces.Box(\n",
        "                low = self.min_action,\n",
        "                high = self.max_action,\n",
        "                shape = (1,) \n",
        "        )\n",
        "\n",
        "        self.observation_space = spaces.Box(-high, high)\n",
        "\n",
        "        self.viewer = None\n",
        "        self.state = None\n",
        "\n",
        "        self.steps_beyond_done = None\n",
        "\n",
        "    def addnoise(self,x):\n",
        "        return {\n",
        "        1 : 0,\n",
        "        2 : self.np_random.uniform(low=-0.05, high=0.05, size=(1,)), #  5% actuator noise ,  small model uniform noise\n",
        "        3 : self.np_random.uniform(low=-0.10, high=0.10, size=(1,)), # 10% actuator noise ,  large model uniform noise\n",
        "        4 : self.np_random.normal(loc=0, scale=np.sqrt(0.10), size=(1,)),                  # small model gaussian noise\n",
        "        5 : self.np_random.normal(loc=0, scale=np.sqrt(0.50), size=(1,)),                 #  large model gaussian noise\n",
        "        6 : self.np_random.uniform(low=-0.05, high=0.05, size=(1,)), #  5% sensor noise ,    small data uniform noise\n",
        "        7 : self.np_random.uniform(low=-0.10, high=0.10, size=(1,)), # 10% sensor noise ,    large data uniform noise\n",
        "        8 : self.np_random.normal(loc=0, scale=np.sqrt(0.10), size=(1,)), # 0.1              small data gaussian noise\n",
        "        9 : self.np_random.normal(loc=0, scale=np.sqrt(0.20), size=(1,)), # 0.2              large data gaussian noise\n",
        "        10: self.np_random.normal(loc = 0, scale = np.sqrt(0.10), size = (1,)),           #  small both gaussian noise\n",
        "        11: self.np_random.normal(loc = 0, scale = np.sqrt(0.50), size = (1,)),          #    large both gaussian noise\n",
        "        }.get(x,1)\n",
        "\n",
        "    def seed(self, seed=None): # Set appropriate seed value\n",
        "        self.np_random, seed = seeding.np_random(seed)\n",
        "        return [seed]\n",
        "\n",
        "    def stepPhysics(self, force):\n",
        "        x, x_dot, theta, theta_dot = self.state\n",
        "        costheta = math.cos(theta)\n",
        "        sintheta = math.sin(theta)\n",
        "        temp = (force + self.polemass_length * theta_dot * theta_dot * sintheta) / self.total_mass\n",
        "        thetaacc = (self.gravity * sintheta - costheta * temp) / \\\n",
        "                    (self.length * (4.0/3.0 - self.masspole * costheta * costheta / self.total_mass))\n",
        "        xacc = temp - self.polemass_length * thetaacc * costheta / self.total_mass\n",
        "        #noise = self.addnoise(self.case) \n",
        "        x  = (x + self.tau * x_dot)\n",
        "        x_dot = (x_dot + self.tau * xacc)\n",
        "        theta = (theta + self.tau * theta_dot)#*(1 + noise)\n",
        "        theta_dot = (theta_dot + self.tau * thetaacc)\n",
        "        return (x, x_dot, theta, theta_dot)\n",
        "\n",
        "\n",
        "    def step(self, action):\n",
        "        assert self.action_space.contains(action), \"%r (%s) invalid\"%(action, type(action))\n",
        "        force = self.force_mag * float(action)\n",
        "        self.state = self.stepPhysics(force)\n",
        "        x, x_dot, theta, theta_dot = self.state\n",
        "\n",
        "        #adding measurement noisy to theta\n",
        "        noise = self.addnoise(self.case)\n",
        "        theta = theta * (1+noise)\n",
        "        noise = self.addnoise(self.case)\n",
        "        x = x*(1+noise)\n",
        "        noise = self.addnoise(self.case)\n",
        "        x_dot = x_dot*(1+noise)\n",
        "        noise = self.addnoise(self.case)\n",
        "        theta_dot = theta_dot*(1+noise)\n",
        "\n",
        "        output_state = (x, x_dot, theta, theta_dot) \n",
        "        output_state = np.array(output_state)  \n",
        "\n",
        "\n",
        "        done = x < -self.x_threshold \\\n",
        "            or x > self.x_threshold \\\n",
        "            or theta < -self.theta_threshold_radians \\\n",
        "            or theta > self.theta_threshold_radians\n",
        "        done = bool(done)\n",
        "\n",
        "        if not done:\n",
        "            reward = 1.0\n",
        "        elif self.steps_beyond_done is None:\n",
        "            # Pole just fell!\n",
        "            self.steps_beyond_done = 0\n",
        "            reward = 1.0\n",
        "        else:\n",
        "            if self.steps_beyond_done == 0:\n",
        "                logger.warn(\"You are calling 'step()' even though this environment has already returned done = True. You should always call 'reset()' once you receive 'done = True' -- any further steps are undefined behavior.\")\n",
        "            self.steps_beyond_done += 1\n",
        "            reward = 0.0\n",
        "\n",
        "        #return np.array(self.state), reward, done, {}\n",
        "        return output_state, reward, done, {}\n",
        "\n",
        "\n",
        "    def reset(self):\n",
        "        self.state = self.np_random.uniform(low=-0.05, high=0.05, size=(4,))\n",
        "        self.steps_beyond_done = None\n",
        "\n",
        "        if self.origin_case<6:          #only model  noise\n",
        "            self.force_mag = 30.0*(1+self.addnoise(self.origin_case))\n",
        "        elif self.origin_case>9:    #both model and data noise\n",
        "            self.force_mag = 30.0*(1+self.addnoise(self.origin_case))\n",
        "        else:               #only data noise\n",
        "            self.force_mag = 30.0\n",
        "\n",
        "\n",
        "        return np.array(self.state)\n",
        "\n",
        "    def render(self, mode='human', close=False):\n",
        "        if close:\n",
        "            if self.viewer is not None:\n",
        "                self.viewer.close()\n",
        "                self.viewer = None\n",
        "            return\n",
        "\n",
        "        screen_width = 600\n",
        "        screen_height = 400\n",
        "\n",
        "        world_width = self.x_threshold*2\n",
        "        scale = screen_width/world_width\n",
        "        carty = 100 # TOP OF CART\n",
        "        polewidth = 10.0\n",
        "        polelen = scale * 1.0\n",
        "        cartwidth = 50.0\n",
        "        cartheight = 30.0\n",
        "\n",
        "        if self.viewer is None:\n",
        "            from gym.envs.classic_control import rendering\n",
        "            self.viewer = rendering.Viewer(screen_width, screen_height)\n",
        "            l,r,t,b = -cartwidth/2, cartwidth/2, cartheight/2, -cartheight/2\n",
        "            axleoffset =cartheight/4.0\n",
        "            cart = rendering.FilledPolygon([(l,b), (l,t), (r,t), (r,b)])\n",
        "            self.carttrans = rendering.Transform()\n",
        "            cart.add_attr(self.carttrans)\n",
        "            self.viewer.add_geom(cart)\n",
        "            l,r,t,b = -polewidth/2,polewidth/2,polelen-polewidth/2,-polewidth/2\n",
        "            pole = rendering.FilledPolygon([(l,b), (l,t), (r,t), (r,b)])\n",
        "            pole.set_color(.8,.6,.4)\n",
        "            self.poletrans = rendering.Transform(translation=(0, axleoffset))\n",
        "            pole.add_attr(self.poletrans)\n",
        "            pole.add_attr(self.carttrans)\n",
        "            self.viewer.add_geom(pole)\n",
        "            self.axle = rendering.make_circle(polewidth/2)\n",
        "            self.axle.add_attr(self.poletrans)\n",
        "            self.axle.add_attr(self.carttrans)\n",
        "            self.axle.set_color(.5,.5,.8)\n",
        "            self.viewer.add_geom(self.axle)\n",
        "            self.track = rendering.Line((0,carty), (screen_width,carty))\n",
        "            self.track.set_color(0,0,0)\n",
        "            self.viewer.add_geom(self.track)\n",
        "\n",
        "        if self.state is None: return None\n",
        "\n",
        "        x = self.state\n",
        "        cartx = x[0]*scale+screen_width/2.0 # MIDDLE OF CART\n",
        "        self.carttrans.set_translation(cartx, carty)\n",
        "        self.poletrans.set_rotation(-x[2])\n",
        "        return self.viewer.render(return_rgb_array = mode=='rgb_array')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9WSrjGyn_vXN"
      },
      "source": [
        "#LLB"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1ZxzfqW_xC7"
      },
      "source": [
        "class BRNN(nn.Module):\n",
        "    def __init__(self, action_dim, hidden_dim, output_dim, device, mode):\n",
        "        super(BRNN, self).__init__()\n",
        "        self.action_dim = action_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.output_dim = output_dim\n",
        "        self.device = device\n",
        "        self.mode = mode\n",
        "\n",
        "        #self.W_added_noise = np.log(2)\n",
        "        self.W_min = np.log(0.1)\n",
        "\n",
        "        init_dim = hidden_dim\n",
        "        emission_dim = hidden_dim\n",
        "\n",
        "        self.initial_encoder = nn.Sequential(\n",
        "            nn.Linear(output_dim, init_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(init_dim, hidden_dim),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "        if mode == 'RNN':\n",
        "            self.transition = nn.RNN(action_dim, hidden_dim)\n",
        "        elif mode == 'LSTM':\n",
        "            self.transition = nn.LSTM(action_dim, hidden_dim)\n",
        "        elif mode == 'GRU':\n",
        "            self.transition = nn.GRU(action_dim, hidden_dim)\n",
        "        else:\n",
        "            raise NotImplementedError\n",
        "        \n",
        "        #self.W_mu = nn.Parameter(torch.Tensor(hidden_dim, hidden_dim + 1).to(self.device), requires_grad=True)\n",
        "        #self.W_logvar = nn.Parameter(torch.Tensor(hidden_dim, hidden_dim + 1).to(self.device), requires_grad=True)\n",
        "        \n",
        "\n",
        "\n",
        "        self.prior_W_mu = torch.zeros_like(torch.Tensor(hidden_dim, hidden_dim+1)).to(self.device)\n",
        "        self.prior_W_mu = nn.init.kaiming_uniform_(self.prior_W_mu, a=math.sqrt(5))\n",
        "\n",
        "        self.prior_W_logvar = torch.ones_like(self.prior_W_mu).to(self.device)           #log var\n",
        "        self.prior_W_logvar = (np.log(0.1)*self.prior_W_logvar).requires_grad_(False)           \n",
        "\n",
        "        self.prior_W_logvar.uniform_(np.log(0.05), np.log(0.1))\n",
        "        #self.prior_W_logvar.uniform_(np.log(0.2), np.log(0.5))\n",
        "\n",
        "        self.W_mu = nn.Parameter(self.prior_W_mu.detach().clone().requires_grad_(True))\n",
        "        self.W_logvar = nn.Parameter(self.prior_W_logvar.detach().clone().requires_grad_(True))  # log(sigma)\n",
        "        #self.W_logvar.data.fill_(np.log(0.5))\n",
        "        #self.W_mu.data = trained_W_mu.clone()\n",
        "        #self.W_logvar.data = trained_W_logvar.clone()\n",
        "\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.emission_mean = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, output_dim)\n",
        "        )\n",
        "\n",
        "        #self.emission_mean = nn.Sequential(\n",
        "        #    nn.Linear(emission_dim, output_dim),\n",
        "        #    nn.Tanh(),\n",
        "        #    nn.Linear(output_dim, output_dim)\n",
        "        #)\n",
        "\n",
        "        #self.x_var =   torch.tensor([1e-2, 1e-2, 1e-2, 1]).to(self.device).requires_grad_(False)\n",
        "        #self.x_var = torch.tensor([0.0025, 1e-1, 0.0025, 1]).to(self.device).requires_grad_(False)\n",
        "\n",
        "        #self.x_var =  torch.tensor([0.0025, 0.0025, 0.0025, 0.25]).to(self.device).requires_grad_(False)\n",
        "\n",
        "\n",
        "        #x_logvar =  torch.log(torch.tensor([1, 1, 1, 1.])).to(self.device)\n",
        "        #self.x_logvar = nn.Parameter(x_logvar.clone().requires_grad_(True))\n",
        "\n",
        "        self.emission_logvar = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "\n",
        "        #self.x_var = torch.tensor([0.0025, 2, 0.0025, 2]).to(self.device).requires_grad_(False)\n",
        "\n",
        "\n",
        "        #self.emission_logvar = nn.Sequential(\n",
        "        #    nn.Linear(emission_dim, output_dim))\n",
        "        #    nn.Tanh(),\n",
        "        #    nn.Linear(output_dim, output_dim),\n",
        "        #    nn.Sigmoid()\n",
        "        #)\n",
        "\n",
        "       # self.scale = nn.Parameter(torch.Tensor(output_dim).requires_grad_(True))\n",
        "        #self.scale.data.fill_(1e-1)\n",
        "\n",
        "        #self.x_var = torch.tensor([1e-4, 1e-6]).to(self.device).requires_grad_(False)\n",
        "\n",
        "\n",
        "\n",
        "        #self.decoder_mean = nn.Sequential(\n",
        "        #    nn.Linear(hidden_dim, output_dim),\n",
        "        #    nn.ReLU(),\n",
        "        #    nn.Linear(output_dim, output_dim)\n",
        "        #)\n",
        "        #self.x_sigma = torch.tensor([1e-4, 1e-6]).to(self.device).requires_grad_(False)\n",
        "\n",
        "        #self.decoder_sigma = nn.Sequential(\n",
        "        #    nn.Linear(hidden_dim, hidden_dim),\n",
        "        #    nn.Tanh(),\n",
        "        #    nn.Linear(hidden_dim, output_dim)\n",
        "        #)\n",
        "\n",
        "\n",
        "\n",
        "        #self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        stdv = 1./math.sqrt(self.W_mu.size(1))\n",
        "        logvar_init = math.log(stdv)*2\n",
        "        self.W_mu.data.uniform_(-stdv, stdv)\n",
        "        self.W_logvar.data.fill_(math.log(0.05))\n",
        "\n",
        "        #nn.init.kaiming_uniform_(self.W_mu, a=math.sqrt(5))\n",
        "        #self.W_sigma.data.fill_(np.log(0.5))\n",
        "\n",
        "\n",
        "    def rollout(self, init_x, A, W_eps = None, track_sigmoid = False, W_uncertainty = True, epsilon_uncertainty = True):\n",
        "        \"\"\"\n",
        "        take initial obs and sequence of actions, output predicted observation mean and variance, \n",
        "        if grad = None, using mean, if not , use posterior sharpening\n",
        "\n",
        "        init_x : [batch, output_dim]\n",
        "        A : [seq-1, batch, 1]\n",
        "        return : observational mean and sigma\n",
        "        \"\"\"\n",
        "        if track_sigmoid:\n",
        "            sigmoid_tracker = []\n",
        "\n",
        "        #forward propagation\n",
        "        init_x = init_x.to(self.device)\n",
        "        A = A.to(self.device)\n",
        "\n",
        "\n",
        "        batch_size = init_x.size(0)\n",
        "        \n",
        "        previous_h = self.initial_encoder(init_x).unsqueeze(0).to(self.device)      #[1, batch ,hidden]\n",
        "        if self.mode == 'LSTM':\n",
        "            previous_c = torch.zeros_like(previous_h).to(self.device)\n",
        "        \n",
        "        #here we follow the BBB paper where they fix the weight for each mini-batch instead of conditioning on single example\n",
        "        #if W_eps is not None:\n",
        "        #    std = torch.exp(0.5 * self.W_logvar)\n",
        "        #    if len(W_eps.shape) > 2:  # Multiple specified samples from W\n",
        "        #        W = self.W_mu.unsqueeze(0).expand(W_eps.shape) + W_eps*std.unsqueeze(0).expand(W_eps.shape)  #  [batch, hid, hid+1]\n",
        "\n",
        "        #    else:\n",
        "        #        W = self.W_mu + W_eps*std\n",
        "\n",
        "        #else:\n",
        "        #    W_eps = torch.rand_like(self.W_logvar).normal_().to(self.device)\n",
        "        #    W = self.W_mu + W_eps*torch.exp(0.5*self.W_logvar)\n",
        "\n",
        "\n",
        "        #eps = torch.FloatTensor(batch_size, self.W_mu.size(0), self.W_mu.size(1)).normal_().to(self.device)\n",
        "        #W =  self.W_mu.unsqueeze(0).expand(eps.shape) + eps*torch.exp(0.5*self.W_logvar).unsqueeze(0).expand(eps.shape)  # [batch, hid, hid+1]\n",
        "\n",
        "\n",
        "        if W_uncertainty:\n",
        "            #clamp_W = torch.clamp(self.W_logvar, self.W_min, np.log(2.0))\n",
        "\n",
        "            W = self.stack_W(batch_size, self.W_mu, torch.exp(0.5 * (self.W_logvar)) )        #[batch, hid, hid+1]\n",
        "        else:\n",
        "            W = self.W_mu.unsqueeze(0).expand(batch_size, self.W_mu.size(0), self.W_mu.size(1))\n",
        "\n",
        "        #W = self.stack_W(batch_size, self.W_mu, torch.exp(0.5*self.W_logvar))        #[batch, hid, hid+1]\n",
        "        #W_sample = self.reparametrise(self.W_mu, torch.exp(self.W_sigma))\n",
        "        #W = W_sample.unsqueeze(0).expand(batch_size, W_sample.size(0), W_sample.size(1))        #[batch, hid, hid+1]\n",
        "\n",
        "\n",
        "        output_mean_list = []\n",
        "        output_cov_list = []\n",
        "        preds = []\n",
        "        for t in range(A.size(0)):\n",
        "            previous_a = A[t].unsqueeze(0)      #[1, batch, 1]\n",
        "            if self.mode == 'LSTM':\n",
        "                current_h, current_c = self.transition(previous_a, (previous_h, previous_c))[-1]   #[1,batch, hidden]\n",
        "            else:\n",
        "                current_h = self.transition(previous_a, previous_h)[-1]     #[1, batch, hidden]\n",
        "\n",
        "\n",
        "            f_t = torch.cat([current_h, torch.ones(current_h.shape[0], current_h.shape[1], 1).to(self.device)], dim = -1)           \n",
        "            f_t = f_t.permute(1,2,0)                #[batch, hid+1, 1]\n",
        "\n",
        "\n",
        "            #one = torch.ones(current_h.squeeze(0).size()[0]).to(self.device)     \n",
        "            #f_t = torch.cat((current_h.squeeze(0), one.unsqueeze(1)), dim = 1)           #[batch, hidden_size + 1]\n",
        "            #next_h = torch.bmm(W, f_t.unsqueeze(-1)).squeeze(-1)         #[batch,hid, hid+1] *[batch, hid+1, 1] ----> [batch, hid]\n",
        "            next_h = torch.bmm(W, f_t).squeeze(-1)\n",
        "            if self.mode == 'GRU':\n",
        "                next_h = torch.tanh(next_h)\n",
        "\n",
        "            temp_emission = self.decoder(next_h)                        #[batch, output]\n",
        "            emission_mean = self.emission_mean(temp_emission)           #[batch, output]\n",
        "            #emission_sigma = torch.sqrt(self.x_var.expand(emission_mean.shape))\n",
        "\n",
        "            #emission_var = self.x_var.expand(emission_mean.shape)       #[batch, output]\n",
        "            #emission_sigma = torch.sqrt(emission_var)                   #[batch, output]\n",
        "            #emission_var = torch.exp(self.x_logvar).expand(emission_mean.size())       #[batch, output]\n",
        "            #emission_sigma = torch.sqrt(emission_var) + 1e-4\n",
        "            emission_var = torch.exp(self.emission_logvar(temp_emission))\n",
        "            emission_sigma = torch.sqrt(emission_var)\n",
        "\n",
        "\n",
        "            #emission_var = torch.exp(self.emission_logvar(temp_emission))   #[batch, output]\n",
        "            #emission_sigma = torch.sqrt(emission_var)\n",
        "\n",
        "            #emission_var= self.emission_logvar(temp_emission)   #* self.scale         #[batch, output]\n",
        "            #emission_sigma = torch.sqrt(emission_var)                  #[batch, output]\n",
        "\n",
        "            if track_sigmoid:\n",
        "                sigmoid_tracker.append(emission_var) \n",
        "\n",
        "\n",
        "            if epsilon_uncertainty:\n",
        "                emission = self.reparametrise(emission_mean, emission_sigma)        #[batch, output]\n",
        "            else:\n",
        "                emission = emission_mean        #[batch, output]\n",
        "\n",
        "\n",
        "                        \n",
        "            preds.append(emission.unsqueeze(0))\n",
        "\n",
        "\n",
        "            #emission_mean = self.decoder_mean(emission)         #[batch, output]\n",
        "            #emission_sigma = torch.exp(self.decoder_sigma(emission))       #[batch, output]\n",
        "            if self.mode == 'LSTM':\n",
        "                previous_c = current_c\n",
        "            previous_h = next_h.unsqueeze(0)\n",
        "\n",
        "            output_mean_list.append(emission_mean.unsqueeze(0))\n",
        "            output_cov_list.append(emission_var.unsqueeze(0))             \n",
        "        output_mean_list = torch.cat(output_mean_list, dim = 0)     #[seq-1, batch, output]\n",
        "        output_cov_list = torch.cat(output_cov_list, dim = 0)       #[seq-1, batch, output]\n",
        "\n",
        "        if track_sigmoid:\n",
        "            sigmoid_list = torch.cat(sigmoid_tracker, dim = 0)      #[seq-1, output]\n",
        "            return torch.cat(preds, dim = 0), output_mean_list, output_cov_list, sigmoid_list\n",
        "\n",
        "        return torch.cat(preds, dim = 0), output_mean_list, output_cov_list\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, X, A, N):\n",
        "        \"\"\"\n",
        "        X : [seq, batch, output_dim]\n",
        "        A : [seq-1, batch, 1]\n",
        "        \"\"\"\n",
        "        X = X.to(self.device)\n",
        "        A = A.to(self.device)\n",
        "        #compute nll\n",
        "        #output_mean, output_std = self.rollout(X[0], A)\n",
        "        #NLL = self.get_nll(output_mean, output_std, X[1:, :, :])        #[batch]\n",
        "        #The gradient of nll\n",
        "        #fix_eps = torch.FloatTensor(X.size(1), self.W_logvar.shape[0], self.W_logvar.shape[1]).normal_().to(self.device)\n",
        "\n",
        "        #forward pass with sharpening posterior weight\n",
        "        _, output_mean, output_cov = self.rollout(X[0], A)\n",
        "\n",
        "        return self.get_loss(output_mean, output_cov, X[1:,...], N)\n",
        "    \n",
        "    def get_loss(self, output_mean, output_sigma, target, N):\n",
        "        \"\"\"\n",
        "        calculate free energy, NLL - KL\n",
        "        output_mean : [seq-1, batch, output]\n",
        "        output_sigma : [seq-1, batch, output]\n",
        "        target : [seq-1, batch, output]\n",
        "\n",
        "        \"\"\"\n",
        "        batch_size = target.size(1)\n",
        "        seq_length = target.size(0)\n",
        "        T = batch_size * seq_length\n",
        "        #LL\n",
        "        flatten_x_mean = output_mean.view(-1, self.output_dim)\n",
        "        flatten_x_std = torch.sqrt(output_sigma).view(-1, self.output_dim)\n",
        "\n",
        "        flatten_target = target.reshape(-1, self.output_dim)\n",
        "\n",
        "        LL = self.batched_gaussian_ll(flatten_x_mean, flatten_x_std, flatten_target)\n",
        "        LL = LL.sum()\n",
        "\n",
        "        #LL = 0.5 * (- T*np.log(2*np.pi) - torch.log(output_sigma).sum()  \n",
        "        #        -  torch.pow(output_sigma, -1).mul(torch.pow(target - output_mean, 2)).sum())        \n",
        "        #print('LL = {}; LL2 = {}'.format(LL.item(), LL2.item()))\n",
        "        #KL\n",
        "        Wprior = Normal(self.prior_W_mu, torch.sqrt(torch.exp(self.prior_W_logvar)))\n",
        "        Wpost = Normal(self.W_mu, torch.sqrt(torch.exp(self.W_logvar)))\n",
        "        KL = kl_divergence(Wpost, Wprior).sum()\n",
        "\n",
        "        #KL = 0.5 * ( self.prior_W_logvar - (self.W_logvar) - 1 \\\n",
        "        #            + torch.exp((self.W_logvar) - self.prior_W_logvar) \\\n",
        "        #            + torch.exp(-self.prior_W_logvar) * torch.pow(self.W_mu - self.prior_W_mu, 2) ).sum()\n",
        "        \n",
        "        #print('KL = {}; KL2 = {}'.format(KL.item(), KL2.item()))\n",
        "\n",
        "        FE = (1/batch_size)*LL - (1/(seq_length*batch_size))*KL\n",
        "        #FE = LL - (1/batch_size)*KL\n",
        "        #FE = LL - (1/batch_size)*KL\n",
        "        return FE, (1/batch_size)*LL, (1/(seq_length*batch_size))*KL\n",
        "        #return FE, LL, (1/batch_size)*KL\n",
        "\n",
        "\n",
        "        '''\n",
        "        #NLL = self.get_nll(output_mean, output_sigma, target)\n",
        "        T = target.size(0)*target.size(1)\n",
        "\n",
        "        LL = 0.5 * (- T*np.log(2*np.pi) - torch.log(output_sigma).sum()  \n",
        "                -  torch.pow(output_sigma, -1).mul(torch.pow(target - output_mean, 2)).sum())\n",
        "        #KL\n",
        "        #KL = self.kl_divergence(self.prior_W_mu, torch.exp(self.prior_W_sigma), self.W_mu, torch.exp(self.W_sigma))\n",
        "        #clamp_W = torch.clamp(self.W_logvar, self.W_min, np.log(2.0))\n",
        "        clamp_W = self.W_logvar\n",
        "\n",
        "        KL = 0.5 * ( self.prior_W_logvar - (clamp_W) - 1 \\\n",
        "                    + torch.exp((clamp_W) - self.prior_W_logvar) \\\n",
        "                    + torch.exp(-self.prior_W_logvar) * torch.pow(self.W_mu - self.prior_W_mu, 2) ).sum()\n",
        "\n",
        "\n",
        "        FE = (1/T)*LL - (1/N)*KL\n",
        "\n",
        "        #KL_sharp = torch.sum((self.sharp_W - self.kl_W).pow(2)/ (2 * 0.002**2))\n",
        "        #KL_sharp = self.kl_divergence(self.phi_container, self.condition_prior_W_sigma, self.sharp_W_mean, self.sharp_W_sigma)\n",
        "\n",
        "        return FE.flatten(), (1/T)*LL.flatten(), (1/N)*KL.flatten()\n",
        "\n",
        "        '''\n",
        "    \n",
        "    def MSE_forward(self, X, A):\n",
        "        X = X.to(self.device)\n",
        "        A = A.to(self.device)\n",
        "\n",
        "        pred, _, _ = self.rollout(X[0], A)      #[seq-1, batch, output]\n",
        "        return pred\n",
        "\n",
        "\n",
        "\n",
        "    def mc_prediction(self, init_X, A, track_sigmoid = False):\n",
        "        \"\"\"\n",
        "\n",
        "        init_X : [1, output]\n",
        "        A : [seq-1, 1, action_dim]\n",
        "\n",
        "        \"\"\"\n",
        "        init_X = init_X.to(self.device)\n",
        "        A = A.to(self.device)\n",
        "        total_list = []\n",
        "        if track_sigmoid:\n",
        "            total_sigmoid_list = []\n",
        "        for i in range(500):\n",
        "            W_eps = 0 #torch.FloatTensor(init_X.size(0), self.W_logvar.shape[0], self.W_logvar.shape[1]).normal_().to(self.device)\n",
        "\n",
        "            if track_sigmoid:\n",
        "                pred, _, _, sigmoid_list= self.rollout(init_X, A, W_eps, track_sigmoid = True)     #[seq-1, 1, output]\n",
        "                total_sigmoid_list.append(sigmoid_list.unsqueeze(-1))     #“seq-1, output, 1]\n",
        "\n",
        "            else:\n",
        "                pred, _, _  = self.rollout(init_X, A, W_eps)\n",
        "\n",
        "            #x_sample = self.reparametrise(output_mean.squeeze(), torch.sqrt(output_sigma).squeeze())\n",
        "            #total_list.append(x_sample.unsqueeze(-1))           #[seq-1, output, 1]\n",
        "            total_list.append(pred.permute(0,2,1))              #[seq-1, output, 1]\n",
        "        total_list = torch.cat(total_list, dim = -1)            #[seq-1, output, 300]\n",
        "        mean = torch.mean(total_list, dim = -1)      #[seq-1, output]\n",
        "        std = torch.std(total_list, dim = -1)       #[seq-1, output]\n",
        "        if track_sigmoid:\n",
        "            total_sigmoid_list = torch.cat(total_sigmoid_list, dim = -1)        #[seq-1, output, 500]\n",
        "            sigmoid_mean = torch.mean(total_sigmoid_list, dim = -1)     #[seq-1, output]\n",
        "            sigmoid_std = torch.std(total_sigmoid_list, dim = -1)         #[seq-1, output]\n",
        "\n",
        "            return mean, std, sigmoid_mean, sigmoid_std\n",
        "        else:\n",
        "            return mean, std\n",
        "\n",
        "    def uncertainty(self, init_X, A, object):\n",
        "        \"\"\"\n",
        "        init_X : [1, output]\n",
        "        A : [seq-1, 1, action_dim]\n",
        "        \"\"\"\n",
        "        init_X = init_X.to(self.device)\n",
        "        A = A.to(self.device)\n",
        "\n",
        "        total_list = []\n",
        "        for i in range(500):\n",
        "            if object == 'W':\n",
        "                pred, _, _= self.rollout(init_X, A, W_uncertainty = True, epsilon_uncertainty = False)\n",
        "            elif object == 'e':\n",
        "                pred, _, _ = self.rollout(init_X, A, W_uncertainty = False, epsilon_uncertainty = True)\n",
        "            elif object == 'both':\n",
        "                pred, _, _ = self.rollout(init_X, A, W_uncertainty = False, epsilon_uncertainty = False)\n",
        "            else:\n",
        "                print('Either W or e')\n",
        "\n",
        "            total_list.append(pred.permute(0,2,1))\n",
        "        total_list = torch.cat(total_list, dim = -1)\n",
        "        mean = torch.mean(total_list, dim = -1)\n",
        "        std = torch.std(total_list, dim = -1)\n",
        "\n",
        "        return mean, std\n",
        "\n",
        "    def imagine(self, init_x, control_f, horizon, plan, W_uncertainty,e_uncertainty):\n",
        "        \"\"\"\n",
        "        init_x : [batch, output_dim]\n",
        "        \"\"\"\n",
        "\n",
        "        batch_size = init_x.size(0)\n",
        "        init_x = init_x.to(self.device)\n",
        "        previous_x = init_x\n",
        "        previous_h = self.initial_encoder(init_x).unsqueeze(0)      #[1, batch, hidden]\n",
        "        if self.mode == 'LSTM':\n",
        "            previous_c = torch.zeros_like(previous_h).to(self.device)       #[1, batch, hidden]\n",
        "        \n",
        "        #different W for each initalisation\n",
        "        if W_uncertainty:\n",
        "            #clamp_W = torch.clamp(self.W_logvar, self.W_min, np.log(2.0))\n",
        "            W = self.stack_W(batch_size, self.W_mu, torch.exp(0.5*self.W_logvar) )        #[batch, hid, hid+1]\n",
        "        else:\n",
        "            W = self.W_mu.unsqueeze(0).expand(batch_size, self.W_mu.size(0), self.W_mu.size(1))\n",
        "\n",
        "\n",
        "\n",
        "        preds = []\n",
        "        action_log_prob_list = []\n",
        "        for t in range(horizon):\n",
        "            if plan == 'pg':\n",
        "                action_samples, action_log_prob = control_f(previous_x)\n",
        "\n",
        "                #action_samples = (action_dist.probs > 0.5).float()  \n",
        "                #action_log_prob = action_dist.log_prob(action_samples)\n",
        "                #action_log_prob_list.append(action_log_prob.unsqueeze(0))\n",
        "\n",
        "                #action_samples = action_dist.sample()                      #[batch, 1]\n",
        "                #compute log prob\n",
        "                action_log_prob_list.append(action_log_prob.unsqueeze(0))           #[1, batch, 1]\n",
        "            elif plan == 'rp':\n",
        "                action_samples, _= control_f(previous_x)          #[batch, 1]\n",
        "                action_log_prob_list = 0\n",
        "            \n",
        "            if self.mode == 'LSTM':\n",
        "                current_h, previous_c = self.transition(action_samples.unsqueeze(0), (previous_h, previous_c))[-1]   #[1,batch, hidden]\n",
        "            else:\n",
        "                current_h = self.transition(action_samples.unsqueeze(0), previous_h)[-1]     #[1, batch, hidden]\n",
        "\n",
        "\n",
        "            f_t = torch.cat([current_h, torch.ones(current_h.shape[0], current_h.shape[1], 1).to(self.device)], dim = -1)           \n",
        "            f_t = f_t.permute(1,2,0)                #[batch, hid+1, 1]\n",
        "\n",
        "            next_h = torch.bmm(W, f_t).squeeze(-1)          #[batch, hidden]\n",
        "            if self.mode == 'GRU':\n",
        "                next_h = torch.tanh(next_h)\n",
        "\n",
        "            temp_emission = self.decoder(next_h)                        #[batch, output]\n",
        "            emission_mean = self.emission_mean(temp_emission)           #[batch, output]\n",
        "            #emission_sigma = torch.sqrt(self.x_var.expand(emission_mean.shape))\n",
        "            if e_uncertainty:\n",
        "                emission_var = torch.exp(self.emission_logvar(temp_emission))\n",
        "                emission_sigma = torch.sqrt(emission_var)\n",
        "\n",
        "                #emission_sigma = torch.sqrt(torch.exp(self.x_logvar).expand(emission_mean.shape))\n",
        "                #emission_sigma = torch.sqrt(self.x_var.expand(emission_mean.shape))                   #[batch, output]\n",
        "                emission = self.reparametrise(emission_mean, emission_sigma)        #[batch, output]\n",
        "            else:\n",
        "                emission = emission_mean\n",
        "            \n",
        "            preds.append(emission.unsqueeze(0))             #[1, batch, output]\n",
        "\n",
        "            previous_h = next_h.unsqueeze(0)\n",
        "            previous_x = emission\n",
        "        \n",
        "        output_list = torch.cat(preds)                  #[seq-1, batch, output]\n",
        "        if plan == 'pg':\n",
        "            action_log_prob_list = torch.cat(action_log_prob_list)  #[seq-1, batch, 1]\n",
        "\n",
        "        return output_list, action_log_prob_list\n",
        "\n",
        "\n",
        "    def validate_by_imagination(self, init_x, control_f, plan, W_uncertainty, e_uncertainty):\n",
        "        \"\"\"\n",
        "        instead of planning with fixed horizon, we let the agent planning as far as it can, \n",
        "        terminating when observations are out of range\n",
        "\n",
        "        init_x : [1, state]\n",
        "        return total reward\n",
        "\n",
        "        \"\"\"\n",
        "        action_list = []\n",
        "\n",
        "        batch_size = init_x.size(0)\n",
        "        init_x = init_x.to(self.device)\n",
        "        previous_x = init_x\n",
        "        previous_h = self.initial_encoder(init_x).unsqueeze(0)      #[1, batch, hidden]\n",
        "        if self.mode == 'LSTM':\n",
        "            previous_c = torch.zeros_like(previous_h).to(self.device)       #[1, batch, hidden]\n",
        "        \n",
        "        #different W for each initalisation\n",
        "        if W_uncertainty:\n",
        "            #clamp_W = torch.clamp(self.W_logvar, self.W_min, np.log(2.0))\n",
        "            W = self.stack_W(batch_size, self.W_mu, torch.exp(0.5*self.W_logvar) )        #[batch, hid, hid+1]\n",
        "        else:\n",
        "            W = self.W_mu.unsqueeze(0).expand(batch_size, self.W_mu.size(0), self.W_mu.size(1))\n",
        "\n",
        "        reward = 0\n",
        "        iter = 0\n",
        "\n",
        "        while True:\n",
        "            \n",
        "            action_samples, _ = control_f(previous_x)       \n",
        "\n",
        "            if self.mode == 'LSTM':\n",
        "                current_h, previous_c = self.transition(action_samples.unsqueeze(0), (previous_h, previous_c))[-1]   #[1,batch, hidden]\n",
        "            else:\n",
        "                current_h = self.transition(action_samples.unsqueeze(0), previous_h)[-1]     #[1, batch, hidden]\n",
        "\n",
        "\n",
        "            f_t = torch.cat([current_h, torch.ones(current_h.shape[0], current_h.shape[1], 1).to(self.device)], dim = -1)           \n",
        "            f_t = f_t.permute(1,2,0)                #[batch, hid+1, 1]\n",
        "\n",
        "            next_h = torch.bmm(W, f_t).squeeze(-1)          #[batch, hidden]\n",
        "            if self.mode == 'GRU':\n",
        "                next_h = torch.tanh(next_h)\n",
        "\n",
        "            temp_emission = self.decoder(next_h)                        #[batch, output]\n",
        "            emission_mean = self.emission_mean(temp_emission)           #[batch, output]\n",
        "            #emission_sigma = torch.sqrt(self.x_var.expand(emission_mean.shape))\n",
        "            if e_uncertainty:\n",
        "                #emission_sigma = torch.sqrt(self.x_var.expand(emission_mean.shape))                   #[batch, output]\n",
        "                #emission = self.reparametrise(emission_mean, emission_sigma)        #[batch, output]\n",
        "                emission_var = torch.exp(self.emission_logvar(temp_emission))\n",
        "                emission_sigma = torch.sqrt(emission_var)\n",
        "                #emission_var = torch.exp(self.x_logvar).expand(emission_mean.size())            #[batch, output]\n",
        "                #emission_sigma = torch.sqrt(emission_var) + 1e-4\n",
        "                emission = self.reparametrise(emission_mean, emission_sigma)        #[batch, output]\n",
        "\n",
        "            else:\n",
        "                emission = emission_mean\n",
        "\n",
        "            reward += 1.\n",
        "            iter += 1\n",
        "\n",
        "            done = emission[:,0] < -2.4 \\\n",
        "                or emission[:,0] > 2.4 \\\n",
        "                or emission[:,2] < -12 * 2 * math.pi / 360 \\\n",
        "                or emission[:,2] > 12 * 2 * math.pi / 360 \\\n",
        "                or iter >= 200\n",
        "            done = bool(done)\n",
        "            #print('state=', emission.data)\n",
        "            #print('done = ',done)\n",
        "            if done:\n",
        "                break           \n",
        "\n",
        "            previous_h = next_h.unsqueeze(0)\n",
        "            previous_x = emission\n",
        "        \n",
        "        return reward\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "    def predict(self, init_X, A):\n",
        "\n",
        "        \n",
        "        init_X = init_X.to(self.device)\n",
        "        A = A.to(self.device)\n",
        "        total_list = []\n",
        "        previous_h = self.initial_encoder(init_X).unsqueeze(0).to(self.device)\n",
        "        if self.mode == 'LSTM':\n",
        "            previous_c = torch.zeros_like(previous_h).to(self.device)\n",
        "        for i in range(500):\n",
        "            temp_pred = []\n",
        "            W = self.reparametrise(self.W_mu, torch.exp(self.W_sigma))         #[hid, hid+1]\n",
        "            for t in range(A.size(0)):\n",
        "                previous_a = A[t].unsqueeze(0)\n",
        "                if self.mode == 'LSTM':\n",
        "                    current_h, current_c = self.transition(previous_a, (previous_h, previous_c))[-1]   #[1,batch, hidden]\n",
        "                else:\n",
        "                    current_h = self.transition(previous_a, previous_h)[1]\n",
        "                one = torch.ones(current_h.squeeze(0).size()[0]).to(self.device)     \n",
        "                f_t = torch.cat((current_h.squeeze(0), one.unsqueeze(1)), dim = 1)           #[batch, hidden_size + 1]\n",
        "\n",
        "                #W = self.reparametrise(self.W_mu, torch.exp(self.W_sigma))         #[hid, hid+1]                \n",
        "                next_h = torch.bmm(W.unsqueeze(0), f_t.unsqueeze(-1)).squeeze(-1)             #[batch, hid, hid+1] * [batch, hid+1, 1] --> [batch, hid]         \n",
        "                \n",
        "                emission = self.decoder(next_h)\n",
        "                emission_mean = self.decoder_mean(emission)     #[1, output]\n",
        "                emission_sigma = torch.exp(self.decoder_sigma(emission))   #[1, output]\n",
        "                #emission_sigma = self.x_sigma.expand(emission_mean.size(0), emission_mean.size(1))\n",
        "\n",
        "                x_sample = self.reparametrise(emission_mean, emission_sigma)       #[1, output]\n",
        "                \n",
        "                #x_sample = self.decoder(next_h)         #[1, output_dim]\n",
        "                temp_pred.append(x_sample)\n",
        "\n",
        "                previous_h = next_h.unsqueeze(0)\n",
        "                if self.mode == 'LSTM':\n",
        "                    previous_c = current_c\n",
        "\n",
        "            temp_pred_vec = torch.cat(temp_pred)    #[seq-1, output_dim]\n",
        "            total_list.append(temp_pred_vec.unsqueeze(-1))          #list of tensor of shape [seq-1, output, 1]\n",
        "        total_list = torch.cat(total_list, dim = -1)     #[seq-1, output_dim, 1000]\n",
        "        mean = torch.mean(total_list, dim = -1)      #[seq-1, output_dim]\n",
        "        std = torch.std(total_list, dim = -1)        #[seq-1, output_dim]\n",
        "\n",
        "        return mean, std\n",
        "    \"\"\"\n",
        "\n",
        "    def batched_gaussian_ll(self, mean, sigma, x):\n",
        "        \"\"\"\n",
        "        log-likelihood of batched observation\n",
        "        mean : shape [batch, output_size]\n",
        "        sigma  : shape [batch, output_size]   (diagonal covariance)\n",
        "        x    : shape [batch, output_size]\n",
        "        the shape of final result is [batch, ]\n",
        "        \"\"\"\n",
        "\n",
        "        if 0 in sigma:\n",
        "            print('Zero occurs in diagonal sigma matrix. (batched gaussian ll)')\n",
        "        if 0 in  sigma**2:\n",
        "            print('Zero occurs after squaring the sigma matrix. (batched gaussian ll)')\n",
        "\n",
        "        inv_diag_cov = self.diagonalise(1/(sigma**2), batch=True)              #a 2d batched matrix----> 3d batched diagonal tensor      \n",
        "\n",
        "\n",
        "        exp = ((x - mean).unsqueeze(-2)) @ inv_diag_cov @ ((x-mean).unsqueeze(-1))      #\n",
        "        exp = exp.squeeze()         #[batch]   \n",
        "        #print(exp) \n",
        "\n",
        "        #if 0 in torch.prod(cov, dim = -1):\n",
        "        #    print('Zero occurs when calculating determinant of diagonal covariance. (batched gaussian ll)')\n",
        "\n",
        "\n",
        "        logdet = torch.sum(2 * torch.log(sigma) , dim = -1)\n",
        "        #logdet = torch.log(torch.prod(sigma**2, dim = -1))         #product of all diagonal variance for each batch, shape [batch]\n",
        "        #print('logdet=', logdet)\n",
        "        n = mean.size()[-1]\n",
        "        \n",
        "        #return - np.log(2*np.pi) - 0.5*logdet - 0.5 * exp \n",
        "\n",
        "        return -(n/2) * np.log(2*np.pi) - 0.5*logdet - 0.5 * exp \n",
        "\n",
        "\n",
        "    def kl_divergence(self, prior_m, prior_sigma, post_m ,post_sigma):\n",
        "        \"\"\"\n",
        "        KL( q || p )\n",
        "        shape : [hidden, hidden+1]\n",
        "        \"\"\"\n",
        "        if 0 in prior_sigma**2:\n",
        "            print('Zero occurs in squaring prior sigma')\n",
        "        if 0 in post_sigma**2:\n",
        "            print('Zero occurs in squaring posterior sigma')\n",
        "\n",
        "        multi_normal_prior = MultivariateNormal(vec(prior_m), self.diagonalise(prior_sigma**2, False))\n",
        "        multi_normal_post = MultivariateNormal(vec(post_m), self.diagonalise(post_sigma**2, False))\n",
        "\n",
        "        return KL_f(multi_normal_post, multi_normal_prior)\n",
        "\n",
        "    \"\"\"\n",
        "    def kl_divergence(self, prior_m, prior_sigma, post_m, post_sigma):\n",
        "\n",
        "        d = prior_m.size(0) * prior_m.size(1)       #hidden*hidden+1\n",
        "        if 0 in prior_sigma**2:\n",
        "            print('Zero occurs in squaring prior sigma')\n",
        "        if 0 in post_sigma**2:\n",
        "            print('Zero occurs in squaring posterior sigma')\n",
        "        vec_prior_m = vec(prior_m)\n",
        "        vec_prior_sigma = vec(prior_sigma)\n",
        "        vec_post_m = vec(post_m)\n",
        "        vec_post_sigma = vec(post_sigma)\n",
        "\n",
        "        trace = ((vec_prior_sigma/vec_post_sigma)**2).sum()\n",
        "\n",
        "        inv_post_diag_cov = self.diagonalise(1/(post_sigma**2), batch=False)        #[hid*hid+1, hid*hid+1]\n",
        "        exp = (vec_post_m - vec_prior_m) @ inv_post_diag_cov @ (vec_post_m - vec_prior_m)  \n",
        "        logdet_prior_cov = (2*torch.log(prior_sigma)).sum()\n",
        "        logdet_post_cov = (2* torch.log(post_sigma)).sum()\n",
        "        logdet = logdet_post_cov - logdet_prior_cov  \n",
        "        return 0.5 * (logdet - d + trace + exp)  \n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    def reparametrise(self, mean, sigma):\n",
        "        \"\"\"\n",
        "        sigma should have the same shape as mean (no correaltion)\n",
        "        \"\"\"\n",
        "        #eps = torch.FloatTensor(sigma).normal_().to('cpu')\n",
        "\n",
        "        eps = torch.rand_like(sigma).normal_().to(self.device)\n",
        "        return mean + sigma*eps\n",
        "    \n",
        "    def stack_W(self, batch_size, mean, sigma):\n",
        "        list_of_W = []\n",
        "        for i in range(batch_size):\n",
        "            temp_W = self.reparametrise(mean, sigma).unsqueeze(0)       #[1, hid, hid+1]\n",
        "\n",
        "            list_of_W.append(temp_W)\n",
        "        return torch.cat(list_of_W)     #[batch_size, hid, hid+1]\n",
        "    \n",
        "    def diagonalise(self, input, batch):\n",
        "        \"\"\"\n",
        "        if input a vector, return a diagonal matrix\n",
        "        if input a non-batched 2d matrix, return a diagonal matrix, eg: [[1,2],[3,4]] ---> diag([1,2,3,4])\n",
        "        if input a batched 2d matrix, return a batched diagonal matrix\n",
        "        if input a 3d batched tensor, return a batched diagonal tensor\n",
        "        \"\"\"\n",
        "        if len(input.size())==1:\n",
        "            return torch.diag(input)\n",
        "        if len(input.size())==2:\n",
        "            if not batch:\n",
        "                return torch.diag(vec(input))\n",
        "            else:\n",
        "                bdiag = torch.Tensor().to(self.device)\n",
        "                for i in range(input.size()[0]):\n",
        "                    bdiag = torch.cat((bdiag, torch.diag(input[i]).unsqueeze(0)), axis = 0)\n",
        "                return bdiag\n",
        "\n",
        "        if len(input.size())==3 and batch:\n",
        "            bdiag = torch.Tensor()\n",
        "            for i in range(input.size()[0]):\n",
        "                bdiag = torch.cat((bdiag, torch.diag(vec(input[i])).unsqueeze(0)), axis = 0)\n",
        "    \n",
        "            return bdiag\n",
        "        else:\n",
        "            print('Dimension of inpout tensor should only be 1,2,3.')\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eFFVsMTY_y_H"
      },
      "source": [
        "#Deterministic controller"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nCpYGxcG_0gw"
      },
      "source": [
        ""
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lDNek5Kh_0jh"
      },
      "source": [
        "class controller(nn.Module):\n",
        "    def __init__(self, action_dim=1, state_dim=4, deterministic = True,device = 'cuda'):\n",
        "        super(controller, self).__init__()\n",
        "        self.action_dim = action_dim\n",
        "        controller_hid = 16\n",
        "        self.state_dim  = state_dim\n",
        "        init_w = 1e-3\n",
        "\n",
        "        self.linear = nn.Sequential(\n",
        "            nn.Linear(self.state_dim,controller_hid),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(controller_hid, controller_hid),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(controller_hid, action_dim)\n",
        "        )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        #if not deterministic:\n",
        "        #    self.std = 0.1\n",
        "        \n",
        "        #self.deterministic = deterministic\n",
        "        \n",
        "        #nn.Linear(self.state_dim, self.action_dim)        #output a p_logits for action 1\n",
        "        self.device = device\n",
        "        self.optimiser = torch.optim.Adam(self.parameters(), lr = 0.001)\n",
        "\n",
        "    def forward(self, state):\n",
        "        \"\"\"\n",
        "        Given states input [batch, state_dim],\n",
        "        \"\"\"\n",
        "        state = state.to(self.device)\n",
        "        #x = F.relu(self.linear1(state))\n",
        "        #x = F.relu(self.linear2(x))\n",
        "        a = self.linear(state)\n",
        "        a =  torch.tanh(a)\n",
        "        log_pi = 0\n",
        "\n",
        "        return a, log_pi\n",
        "\n",
        "\n",
        "        #out_mean = self.linear(state)         #[batch, action_dim]\n",
        "        \n",
        "        #if not self.deterministic:\n",
        "        #    eps = torch.rand_like(out_mean).normal_().to(self.device)           #[batch, action_dim]\n",
        "        #    out = out_mean + self.std * eps\n",
        "        #else:\n",
        "        #    out = out_mean\n",
        "\n",
        "        #if len(out.shape) == 1:\n",
        "        #    out = torch.clamp(out, -1, 1)\n",
        "        #else:\n",
        "        #    out = torch.clamp(out[:,0], -1, 1).unsqueeze(1)             #[1, batch, 1]\n",
        "\n",
        "        #return torch.tanh(out)\n",
        "\n",
        "\n",
        "        #if len(out.shape) == 1:\n",
        "        #    return torch.clamp(out, -1, 1)\n",
        "        #else:\n",
        "        #    clamp_out = torch.clamp(out[:, 0], -1, 1).unsqueeze(-1)\n",
        "        #    return clamp_out\n",
        "    \n",
        "    def make_decision(self, state, behaviour_uncertainty):\n",
        "        \"\"\"\n",
        "        given a state [batch, state_dim], output a action\n",
        "        \"\"\"\n",
        "        state = state.to(self.device)\n",
        "        #x = F.relu(self.linear1(state))\n",
        "        #x = F.relu(self.linear2(x))\n",
        "        a = self.linear(state)\n",
        "        a = torch.tanh(a)\n",
        "\n",
        "        return a.detach()\n",
        "\n",
        "        #out_mean = self.linear(state)\n",
        "        #if not self.deterministic and behaviour_uncertainty:\n",
        "        #    eps = torch.rand_like(out_mean).normal_().to(self.device) \n",
        "        #    out = out_mean + self.std * eps\n",
        "        #else:\n",
        "        #    out = out_mean\n",
        "        #if len(out.shape) == 1:\n",
        "\n",
        "        #    out = torch.clamp(out, -1, 1)\n",
        "        #else:\n",
        "        #    out = torch.clamp(out[:,0], -1, 1)\n",
        "        #return out.detach()\n",
        "        #return torch.tanh(out)\n",
        "    def pg_train(self, num_epoch, initial_state, horizon, cost_f, model_imagine_f, w_uncertainty, e_uncertainty,gamma = 0.95):\n",
        "        \"\"\"\n",
        "        initial_state : [batch, state_dim]\n",
        "\n",
        "        \"\"\"\n",
        "        loss_list = []\n",
        "        num_particle = 100\n",
        "        initial_state = initial_state.expand(num_particle, self.state_dim)\n",
        "\n",
        "        for e in range(num_epoch):\n",
        "            output_matrix, action_log_prob_matrix = model_imagine_f(initial_state, self.forward, horizon, plan = 'pg',\n",
        "                                                                    W_uncertainty = w_uncertainty, e_uncertainty = e_uncertainty)\n",
        "            cost = cost_f(output_matrix).detach()               #[seq-1, batch, 1]  \n",
        "            \n",
        "            cost = cost * torch.tensor([gamma**(t+1) for t in range(cost.size(0))]).unsqueeze(-1).unsqueeze(-1).to(self.device)\n",
        "\n",
        "            #baseline = torch.mean(cost, dim = 0).unsqueeze(0)       #[1, batch, 1]\n",
        "            #cost = cost - torch.mean(cost, dim = 0).unsqueeze(0)\n",
        "            #loss = ((cost-baseline) * action_log_prob_matrix).sum(0)\n",
        "            loss = cost.sum(0) * action_log_prob_matrix.sum(0) \n",
        "\n",
        "            loss = loss.sum()\n",
        "            loss.backward()\n",
        "            nn.utils.clip_grad_norm_(self.parameters(), 5)\n",
        "\n",
        "            self.optimiser.step()\n",
        "            loss_list.append(loss.item())\n",
        "            if e%50 == 0:\n",
        "                print('Epoch = {}; Policy gradient training loss = {}'.format(e, loss.item()))\n",
        "        return loss_list\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    \n",
        "    def rp_train(self, num_epoch, num_particle,initial_state, horizon , cost_f, model_imagine_f, w_uncertainty, e_uncertainty,gamma = 0.9):\n",
        "        \"\"\"\n",
        "        From an initial state, use mode imagination function to make prediction of the next state accordin to the action proposed by\n",
        "        the controller, we fixed the horizon and compute the total reward of the trajectory, from which the gradient w.r.t policy \n",
        "        parameters is taken.\n",
        "        inital_state: [batch, output_dim]\n",
        "        \"\"\"\n",
        "        loss_list = []\n",
        "        num_particle = num_particle\n",
        "        initial_state = initial_state.expand(num_particle, self.state_dim)\n",
        "\n",
        "        cost_mean_list = []\n",
        "        cost_std_list = []\n",
        "        \n",
        "        for e in range(num_epoch):\n",
        "            self.optimiser.zero_grad()\n",
        "            output_matrix, action_matrix= model_imagine_f(initial_state, self.forward, horizon, plan = 'rp',\n",
        "                                              W_uncertainty = w_uncertainty,e_uncertainty = e_uncertainty) \n",
        "            \n",
        "            self.action_matrix = action_matrix\n",
        "            self.temp_output_matrix = torch.cat([initial_state.unsqueeze(0).to(self.device), output_matrix], dim = 0)\n",
        "\n",
        "            cost = cost_f(output_matrix)                 #[seq-1, batch, 1]  \n",
        "\n",
        "            mean_cost = cost.data.sum(0).mean(0)      #[]\n",
        "            std_cost = cost.data.sum(0).std(0)\n",
        "            cost_mean_list.append(mean_cost)\n",
        "            cost_std_list.append(std_cost)\n",
        "\n",
        "            #multiply by discount factor\n",
        "            #cost = cost *  ((torch.arange(cost.size(0)+1,1,-1).float()).unsqueeze(-1).unsqueeze(-1)/cost.size(0)\n",
        "            #                    ).expand(cost.shape).float().to(self.device)\n",
        "            \n",
        "            cost = cost * torch.tensor([gamma**(t+1) for t in range(cost.size(0))]).unsqueeze(-1).unsqueeze(-1).to(self.device)\n",
        "\n",
        "            loss = cost.sum()      #[batch, 1]\n",
        "            #loss = torch.exp(action_log_prob_matrix.sum(0)) * cost.sum(0)\n",
        "            #loss = (cost * action_log_prob_matrix).sum(0)                 #[batch, 1]\n",
        "            loss.backward()\n",
        "\n",
        "            nn.utils.clip_grad_norm_(self.parameters(), 1)\n",
        "            self.optimiser.step()\n",
        "            loss_list.append(loss.item())\n",
        "            #print('policy loss = {}', loss.item())\n",
        "            #print('Epoch = {}; Policy gradient training loss = {}; Cost: mean {} std {}.'.format(e, loss.item()/num_particle,\n",
        "            #                                                                                        mean_cost.item(), std_cost.item()))\n",
        "\n",
        "\n",
        "        return loss_list, torch.cat(cost_mean_list), torch.cat(cost_std_list)\n",
        "\n",
        "    def rp_validate(self, num_particle, initial_state, horizon, cost_f, model_imagine_f, w_uncertainty, e_uncertainty, gamma = 1):\n",
        "        initial_state = initial_state.expand(num_particle, self.state_dim)\n",
        "        output_matrix, action_matrix= model_imagine_f(initial_state, self.forward, horizon, plan = 'rp',\n",
        "                                              W_uncertainty = w_uncertainty,e_uncertainty = e_uncertainty) \n",
        "        cost = cost_f(output_matrix)\n",
        "\n",
        "        mean_cost = cost.data.sum(0).mean(0)\n",
        "        return mean_cost.item()\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ymAmAt8_4vG"
      },
      "source": [
        "#Agent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RG1x7P5m_brh"
      },
      "source": [
        "class Agent:\n",
        "    def __init__(self, env_case, state_dim = 4, action_dim = 1, model = 'LLB',deterministic = True,device='cuda', rand_seed = 1):\n",
        "        \n",
        "        self.env = CartPoleModEnv(case = env_case)\n",
        "        self.env_case = env_case\n",
        "        #self.env = gym.make('CartPole-BT-dH-v0')\n",
        "        #self.env = gym.make('CartPoleMod-v2')\n",
        "\n",
        "        self.state_dim = state_dim\n",
        "        self.action_dim = action_dim\n",
        "        self.device = device\n",
        "        self.observations_list = []\n",
        "        self.actions_list= []\n",
        "        self.MSEloss = nn.MSELoss()\n",
        "        self.model_name = model\n",
        "\n",
        "        if model == 'DRNN':\n",
        "            self.model = DRNN(action_dim, 32, state_dim, device, 'LSTM').to(device)\n",
        "        elif model == 'SRNN':\n",
        "            self.model = SRNN(action_dim, 32, state_dim, device, 'LSTM', noise = 0.5 * torch.tensor([0.1,0.1,0.1,1])).to(device)\n",
        "        elif model == 'LLB':\n",
        "            self.model = BRNN(action_dim, 32, state_dim, device, 'LSTM').to(device)\n",
        "\n",
        "        self.model_optimiser = torch.optim.Adam(self.model.parameters(), lr = 0.001)\n",
        "        self.mseloss = nn.MSELoss()\n",
        "        self.model_training_loss_list = []\n",
        "\n",
        "        self.policy = controller(action_dim, state_dim, device).to(device)\n",
        "        self.deterministic_policy = deterministic\n",
        "\n",
        "        #np.random.seed(rand_seed)\n",
        "        #self.env.seed(rand_seed)\n",
        "        #torch.manual_seed(rand_seed)\n",
        "\n",
        "    \n",
        "    def env_rollout(self, if_remember, plan, behaviour_uncertainty):\n",
        "        \"\"\"\n",
        "        interaction with the environment using the current policy. \n",
        "        \"\"\"\n",
        "        done = False\n",
        "        state = self.env.reset()\n",
        "        total_reward = 0\n",
        "        i = 0\n",
        "        temp_obs_list = []\n",
        "        temp_actions_list = []\n",
        "\n",
        "        if if_remember:\n",
        "            temp_obs_list.append(torch.tensor(state))\n",
        "        \n",
        "        while not done:\n",
        "            i+=1\n",
        "            \n",
        "            if plan == 'random':\n",
        "                action = self.env.action_space.sample()\n",
        "            elif plan == 'pg' or 'rp':\n",
        "\n",
        "                state_tensor = torch.tensor(np.vstack(state)).float().squeeze()\n",
        "\n",
        "                action = self.policy.make_decision(state_tensor.to(self.device), behaviour_uncertainty)\n",
        "                action = action.detach().cpu().numpy()\n",
        "\n",
        "                \n",
        "            else:\n",
        "                raise NotImplementedError\n",
        "            #print('action = ', action)\n",
        "\n",
        "            #next_state, reward, done, _  = self.env.step(int(action))\n",
        "            next_state, reward, _, _  = self.env.step(action)\n",
        "\n",
        "            #print('next state = ', next_state)\n",
        "\n",
        "            done = next_state[0] < -2.4 \\\n",
        "                or next_state[0] > 2.4 \\\n",
        "                or next_state[2] < -12 * 2 * math.pi / 360 \\\n",
        "                or next_state[2] > 12 * 2 * math.pi / 360 \\\n",
        "                or i >= 200\n",
        "            \n",
        "            #print('done = ', done)\n",
        "\n",
        "            if if_remember:\n",
        "\n",
        "                temp_obs_list.append(torch.tensor(np.vstack(next_state)).squeeze())\n",
        "\n",
        "                #temp_obs_list.append(torch.tensor(next_state))\n",
        "\n",
        "\n",
        "                temp_actions_list.append(torch.tensor(action).float())\n",
        "            \n",
        "            state = next_state\n",
        "            total_reward += 1\n",
        "\n",
        "            #if total_reward > 200:\n",
        "            #    break\n",
        "\n",
        "        if if_remember:\n",
        "            self.observations_list.append(torch.stack(temp_obs_list).float())       #list of shape [seq, output]\n",
        "            self.actions_list.append(torch.stack(temp_actions_list).float())        #list of shape [seq-1, 1]\n",
        "\n",
        "        return total_reward\n",
        "    \n",
        "    def model_learning(self, num_epoch, num_batch):\n",
        "        \"\"\"\n",
        "        perform model leanring using data self.observation_list and self.actions_list; since the data has variable length, one could \n",
        "        try truncate the data into same length or pack_padded_sequence, but here we would simply train each single sample in a batch,\n",
        "        and during each epoch, the parameter is only updated once using part of the dataset\n",
        "        num_epoch : number of training epoch\n",
        "        num_batch: this is actually number of samples we want the model to be trained on during each epoch\n",
        "        \"\"\"\n",
        "\n",
        "\n",
        "\n",
        "        for e in range(num_epoch):\n",
        "            self.model_optimiser.zero_grad()\n",
        "\n",
        "            idx = np.random.choice(len(self.observations_list), num_batch)\n",
        "            trun_obs = truncate_sequence([self.observations_list[i] for i in idx], batch_first = False)\n",
        "            trun_actions = truncate_sequence([self.actions_list[j] for j in idx], batch_first = False)\n",
        "            \n",
        "            if self.model_name == 'DRNN':\n",
        "                pred = self.model(trun_obs[0,:,:], trun_actions)\n",
        "            elif self.model_name == 'SRNN':\n",
        "                pred, _, _ = self.model(trun_obs[0, :, :], trun_actions)\n",
        "            elif self.model_name == 'LLB':\n",
        "                N = int(trun_actions.numel())\n",
        "                b_FE, b_LL, b_KL = self.model(trun_obs, trun_actions, N)\n",
        "                loss = -b_FE\n",
        "            if self.model_name is not 'LLB':    \n",
        "                loss = self.MSEloss(torch.cat(pred), trun_obs[1:,:,:].to('cuda'))\n",
        "            loss.backward()\n",
        "\n",
        "            \n",
        "\n",
        "            #for i in idx:\n",
        "            #    training_obs = self.observations_list[i].unsqueeze(1)       #[seq, 1, output]\n",
        "            #    training_actions = self.actions_list[i]                      #[seq-1, 1]\n",
        "\n",
        "            #    pred = self.model(training_obs[0,:,:], training_actions.unsqueeze(-1))\n",
        "            #    loss = self.mseloss(torch.cat(pred).unsqueeze(1), training_obs[1:, :, :].to(self.device))\n",
        "            #    temp_loss += loss\n",
        "            #temp_loss.backward()\n",
        "\n",
        "            self.model_optimiser.step()\n",
        "            self.model_training_loss_list.append(loss.item())\n",
        "\n",
        "            if e%1000 == 0:\n",
        "                if self.model_name == 'LLB':\n",
        "                    print('Epoch{}; FE = {}; LL = {}; KL = {}.'.format(e, b_FE.item(), b_LL.item(), b_KL.item()))\n",
        "                else:\n",
        "                    print('Epoch:{}; loss = {}.'.format(e, loss.item()))\n",
        "\n",
        "\n",
        "    def cost(self, state):\n",
        "        \"\"\"\n",
        "        cost = 5*angle^2 + position^2\n",
        "        state : [seq, batch, output]\n",
        "        return [seq, batch, 1]\n",
        "        \"\"\"\n",
        "        return (5*state[:,:,2]**2 + state[:,:,0]**2).unsqueeze(-1)      #[seq, batch, 1]\n",
        "\n",
        "    '''\n",
        "    def cost(self, states, sigma=0.25):\n",
        "        \"\"\"\n",
        "        states : [seq, batch, output]\n",
        "        return : [seq, batch, 1]\n",
        "        \"\"\"\n",
        "        l = 0.6\n",
        "        seq_length = states.size(0)\n",
        "        batch_size = states.size(1)\n",
        "        feature_dim = states.size(-1)\n",
        "        \n",
        "        goal = Variable(torch.FloatTensor([0.0, l])).unsqueeze(0).unsqueeze(0).expand(seq_length,1, 2).to(self.device)     #[seq, 1,2]\n",
        "\n",
        "        # Cart position\n",
        "        cart_x = states[:,:, 0]         #[seq, batch]\n",
        "        # Pole angle\n",
        "        thetas = states[:,:,2]          #[seq, bnatch]\n",
        "        # Pole position\n",
        "        x = torch.sin(thetas)*l         #[seq, batch]\n",
        "        y = torch.cos(thetas)*l\n",
        "        positions = torch.stack([cart_x + x, y], -1)             #[seq, batch, 2]\n",
        "\n",
        "        \n",
        "        squared_distance = torch.sum((goal - positions)**2, -1).unsqueeze(-1)          #[]\n",
        "\n",
        "        squared_sigma = sigma**2\n",
        "        cost = 1 - torch.exp(-0.5*squared_distance/squared_sigma)\n",
        "        \n",
        "        return cost\n",
        "    '''\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def policy_learning(self, imagine_num, num_particle,num_epoch, batch_size, horizon, plan, w_uncertainty, e_uncertainty, plot=False):\n",
        "        \"\"\"\n",
        "        we utilise the current learned model to do policy learning on imagined data\n",
        "        num_epoch : number of epochs we want to run our policy gradient for\n",
        "        batch_size : number of samples we want to train the policy on/ number of initial states\n",
        "\n",
        "        we creat batch_size number of initial state, the model then rollout for a fixed length(horizon), the sum of cost for each \n",
        "        imagined trajectory is computed, from which the gradient is taken w.r.t the policy parameters\n",
        "        \"\"\"\n",
        "        #creat inital states \n",
        "        for i in range(imagine_num):\n",
        "            #initial_state = []\n",
        "            #for b in range(batch_size):\n",
        "            #    init_x = self.env.reset()\n",
        "            #    initial_state.append(torch.tensor(init_x).float())\n",
        "            #initial_state = torch.stack(initial_state)          #[batch, output]\n",
        "            initial_state = torch.tensor(self.env.reset()).unsqueeze(0).float()         #[1, output]\n",
        "            if plot:\n",
        "                initial_state = torch.zeros_like(initial_state)\n",
        "            #initial_state = torch.tensor(np.array([ 0.04263216,  0.00452452, -0.03763419, -0.03992425])).float().unsqueeze(0)\n",
        "\n",
        "            #learn the policy parameter using current model\n",
        "\n",
        "            model_f = self.model.imagine\n",
        "\n",
        "            if plan == 'pg':\n",
        "                policy_train_loss = self.policy.pg_train(num_epoch, num_particle,initial_state, horizon , self.cost, model_f, \n",
        "                                                         w_uncertainty, e_uncertainty,gamma=1)\n",
        "            elif plan == 'rp':\n",
        "                policy_train_loss = self.policy.rp_train(num_epoch, num_particle,initial_state, horizon, self.cost, model_f, \n",
        "                                                         w_uncertainty, e_uncertainty,gamma = 1)\n",
        "        self.policy_loss = policy_train_loss\n",
        "        \"\"\"\n",
        "        total_reward = []\n",
        "        for i in range(20):\n",
        "            init_x = torch.tensor(self.env.reset()).unsqueeze(0).float() \n",
        "\n",
        "            imagine_reward = self.model.validate_by_imagination(init_x, self.policy.forward, \n",
        "                                                            plan, w_uncertainty, e_uncertainty)\n",
        "            total_reward.append(imagine_reward)\n",
        "            #print('temp reward', imagine_reward)\n",
        "        mean_reward = np.mean(total_reward)\n",
        "        std_reward = np.std(total_reward)\n",
        "        print('Training reward: mean {}, std {}.'.format(mean_reward, std_reward))\n",
        "        return mean_reward, std_reward\n",
        "\n",
        "        \"\"\"\n",
        "        \"\"\"\n",
        "        total_cost10 = []\n",
        "        total_cost100= []\n",
        "        for i in range(20):\n",
        "            initial_state = torch.tensor(self.env.reset()).unsqueeze(0).float()         #[1, output]\n",
        "            mean_cost10 = self.policy.rp_validate(num_particle, initial_state, 10, self.cost, model_f, w_uncertainty, e_uncertainty)\n",
        "            mean_cost100 = self.policy.rp_validate(num_particle, initial_state, 100, self.cost, model_f, w_uncertainty, e_uncertainty)\n",
        "\n",
        "            total_cost10.append(mean_cost10)\n",
        "            total_cost100.append(mean_cost100)\n",
        "\n",
        "        mean_cost10 = np.mean(total_cost10)\n",
        "        std_cost10 = np.std(total_cost10)\n",
        "\n",
        "        mean_cost100 = np.mean(total_cost100)\n",
        "        std_cost100 = np.std(total_cost100)\n",
        "\n",
        "\n",
        "        return mean_cost10, std_cost10, mean_cost100, std_cost100\n",
        "\n",
        "        \"\"\"\n",
        "        \"\"\"\n",
        "        total_cost10 = []\n",
        "        for i in range(20):\n",
        "            initial_state = torch.tensor(self.env.reset()).unsqueeze(0).float()         #[1, output]\n",
        "            mean_cost = self.policy.rp_validate(num_particle, initial_state, 10, self.cost, model_f, w_uncertainty, e_uncertainty, gamma=1)\n",
        "            total_cost10.append(mean_cost)\n",
        "\n",
        "        mean_cost10 = np.mean(total_cost10)\n",
        "        std_cost10 = np.std(total_cost10)\n",
        "\n",
        "        total_cost100 = []\n",
        "        for i in range(20):\n",
        "            initial_state = torch.tensor(self.env.reset()).unsqueeze(0).float()         #[1, output]\n",
        "            mean_cost = self.policy.rp_validate(num_particle, initial_state, 100, self.cost, model_f, w_uncertainty, e_uncertainty, gamma=1)\n",
        "            total_cost100.append(mean_cost)\n",
        "\n",
        "        mean_cost100 = np.mean(total_cost100)\n",
        "        std_cost100 = np.std(total_cost100)\n",
        "\n",
        "\n",
        "        return mean_cost10, std_cost10, mean_cost100, std_cost100\n",
        "        \"\"\"\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vs-NP6im_7yb"
      },
      "source": [
        "#Learning-Planning iterations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJ41oszn_-Ru",
        "outputId": "a8bbb9b3-d595-48b1-f49c-f473419af9a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "time1 = time.time()\n",
        "testing_reward_list = []\n",
        "behaviour_uncertainty = True\n",
        "deterministic = False\n",
        "plan = 'rp'\n",
        "num_data = 10\n",
        "\n",
        "#mean_training_reward_list = []\n",
        "#std_training_reward_list = []\n",
        "torch.manual_seed(1)\n",
        "\n",
        "agent = Agent(env_case = 1, deterministic = deterministic,device = 'cuda', model = 'LLB')\n",
        "for i in range(num_data):\n",
        "     _ = agent.env_rollout(True, behaviour_uncertainty = behaviour_uncertainty,plan = 'random')\n",
        "\n",
        "agent.model_learning(num_epoch=1000, num_batch = 10)\n",
        "#agent.model = BRNN_model\n",
        "\n",
        "agent.policy_learning(imagine_num=50, num_particle = 1000, num_epoch = 1, \n",
        "                      batch_size = 10, horizon = 10, plan = plan, w_uncertainty = True, e_uncertainty = True)\n",
        "\n",
        "#mean_training_reward_list.append(mean_training_reward)\n",
        "#std_training_reward_list.append(std_training_reward)\n",
        "\n",
        "print('\\n ------------------TESTING-------------------')\n",
        "#over 10 trails\n",
        "avg_rewards = 0\n",
        "for j in range(20):\n",
        "    rewards = agent.env_rollout(if_remember=False, behaviour_uncertainty = behaviour_uncertainty,plan = plan)\n",
        "    print(j, rewards)\n",
        "    avg_rewards += rewards\n",
        "avg_rewards = avg_rewards/20\n",
        "testing_reward_list.append(avg_rewards)\n",
        "print('Total trajs:', j, avg_rewards)\n",
        "if avg_rewards >= 200:\n",
        "    print('success')\n",
        "        \n",
        "#testing_reward_list = []\n",
        "#mean_training_reward_list = []\n",
        "#std_training_reward_list = []\n",
        "#agent.policy = controller(1, 4, 'cuda').to('cuda')\n",
        "avg_data_length_list = []\n",
        "\n",
        "for i in range(50):\n",
        "    print('Epoch = ',i+1)\n",
        "\n",
        "    _ = agent.env_rollout(True, behaviour_uncertainty = behaviour_uncertainty,plan = plan)\n",
        "\n",
        "    total = 0\n",
        "    for i in range(len(agent.observations_list)):\n",
        "        total += len(agent.observations_list[i])\n",
        "    print('average training data length = ', total/len(agent.observations_list))\n",
        "    avg_data_length_list.append(total/len(agent.observations_list))\n",
        "\n",
        "    print('\\n Begin model learning...')\n",
        "    agent.model_learning(num_epoch =  1000, num_batch = 10)\n",
        "    print('\\n Finish model learning...')\n",
        "\n",
        "    #agent.policy = controller(1, 4, 'cuda').to('cuda')\n",
        "    agent.policy_learning(imagine_num=50, num_particle = 1000, num_epoch = 1, \n",
        "                          batch_size = 10, horizon = 10, plan = plan, w_uncertainty = True, e_uncertainty = True )\n",
        "    #mean_training_reward_list.append(mean_training_reward)\n",
        "    #std_training_reward_list.append(std_training_reward)\n",
        "    print('\\n Finish policy learning...')\n",
        "\n",
        "    print('\\n ------------------TESTING-------------------')\n",
        "    #over 10 trails\n",
        "    avg_rewards = 0\n",
        "    for j in range(20):\n",
        "        rewards = agent.env_rollout(if_remember=False, behaviour_uncertainty = behaviour_uncertainty,plan = plan)\n",
        "        print(j, rewards)\n",
        "        avg_rewards += rewards\n",
        "    avg_rewards = avg_rewards/20\n",
        "    testing_reward_list.append(avg_rewards)\n",
        "    print('Total trajs:', j, avg_rewards)\n",
        "    if avg_rewards > 200:\n",
        "        print('success')\n",
        "time2 = time.time()\n",
        "print(time2 - time1)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CartPoleModEnv - Version 0.2.0, Noise case: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
            "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch0; FE = -43.0851936340332; LL = -43.0851936340332; KL = 0.0.\n",
            "\n",
            " ------------------TESTING-------------------\n",
            "0 25\n",
            "1 22\n",
            "2 18\n",
            "3 21\n",
            "4 25\n",
            "5 16\n",
            "6 19\n",
            "7 22\n",
            "8 23\n",
            "9 18\n",
            "10 21\n",
            "11 17\n",
            "12 24\n",
            "13 20\n",
            "14 27\n",
            "15 20\n",
            "16 17\n",
            "17 17\n",
            "18 21\n",
            "19 23\n",
            "Total trajs: 19 20.8\n",
            "Epoch =  1\n",
            "average training data length =  25.181818181818183\n",
            "\n",
            " Begin model learning...\n",
            "Epoch0; FE = 25.531444549560547; LL = 27.623550415039062; KL = 2.092106342315674.\n",
            "\n",
            " Finish model learning...\n",
            "\n",
            " Finish policy learning...\n",
            "\n",
            " ------------------TESTING-------------------\n",
            "0 33\n",
            "1 31\n",
            "2 37\n",
            "3 38\n",
            "4 49\n",
            "5 29\n",
            "6 48\n",
            "7 53\n",
            "8 34\n",
            "9 45\n",
            "10 38\n",
            "11 69\n",
            "12 30\n",
            "13 42\n",
            "14 41\n",
            "15 59\n",
            "16 53\n",
            "17 59\n",
            "18 49\n",
            "19 41\n",
            "Total trajs: 19 43.9\n",
            "Epoch =  2\n",
            "average training data length =  25.75\n",
            "\n",
            " Begin model learning...\n",
            "Epoch0; FE = 34.811622619628906; LL = 38.47646713256836; KL = 3.6648433208465576.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-7c3cc96363c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n Begin model learning...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m     \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_learning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epoch\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n Finish model learning...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-c355989f2170>\u001b[0m in \u001b[0;36mmodel_learning\u001b[0;34m(self, num_epoch, num_batch)\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_name\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'LLB'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m                 \u001b[0mN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrun_actions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m                 \u001b[0mb_FE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_LL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_KL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrun_obs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrun_actions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mb_FE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_name\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m'LLB'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-734ec0a1e168>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, X, A, N)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_cov\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrollout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_cov\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_sigma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-734ec0a1e168>\u001b[0m in \u001b[0;36mget_loss\u001b[0;34m(self, output_mean, output_sigma, target, N)\u001b[0m\n\u001b[1;32m    280\u001b[0m         \u001b[0mflatten_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m         \u001b[0mLL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatched_gaussian_ll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflatten_x_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflatten_x_std\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflatten_target\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m         \u001b[0mLL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}